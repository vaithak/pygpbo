{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AleboGP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1n3QPLfkDBW",
        "outputId": "9a7cc5a9-a79f-44c6-b70a-433ae96d2d21"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "!pip install gpytorch\n",
        "!pip install adabound\n",
        "import gpytorch\n",
        "from gpytorch.kernels.rbf_kernel import postprocess_rbf\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from collections import OrderedDict\n",
        "import copy\n",
        "import adabound"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from gpytorch) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gpytorch) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->gpytorch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->gpytorch) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->gpytorch) (1.0.1)\n",
            "Requirement already satisfied: adabound in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabound) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabound) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabound) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4GTLXyml8iS"
      },
      "source": [
        "\n",
        "def function(X,noise=0):\n",
        "  def func(x):\n",
        "    return (math.pow((x[1]-5.1/(4*math.pow(3.14,2))*math.pow(x[0],2)+5/3.14*x[0]-6),2)+10*(1-1/(8*3.14))*math.cos(x[0])+10)*math.sin(x[2]/5)\n",
        "  return torch.tensor(np.apply_along_axis(func, 1, X).reshape(-1,1),dtype = torch.float32)\n",
        "\n",
        "batch_shape = torch.Size([1])\n",
        "a1 = torch.linspace(-5, 10, 4)\n",
        "a2 = torch.linspace(0, 15, 4)\n",
        "a3 = torch.linspace(-5,5,4)\n",
        "train_x = torch.zeros((4*4*4,3),dtype=torch.float32)\n",
        "ctr=0\n",
        "for i1 in a1:\n",
        "    for i2 in a2:\n",
        "        for i3 in a3:\n",
        "            train_x[ctr,0] = i1\n",
        "            train_x[ctr,1] = i2\n",
        "            train_x[ctr,2] = i3\n",
        "            ctr+=1\n",
        "\n",
        "def get_proj_matrix(D,d,hypersphere=0):\n",
        "  ''' Takes three arguments D : column size, d : row size and hypersphere = 0/1 (if hypersphere is 1 then sample each row of B from S^{D-1} else from N(0,1))\n",
        "  returns a random B matrix of shape d x D '''\n",
        "  A = np.random.normal(0,1,(d,D))\n",
        "  if hypersphere==1:\n",
        "    for row in range(d):\n",
        "      N = np.linalg.norm(A[row,:])\n",
        "      A[row,:] = A[row,:]/N\n",
        "  return A\n",
        "\n",
        "B = torch.tensor(get_proj_matrix(3,2,1),dtype=torch.float32)\n",
        "train_x_d = (train_x @ B.t())\n",
        "train_y = function(train_x)\n",
        "train_y = train_y.squeeze(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AleboKernel(gpytorch.kernels.Kernel):\n",
        "  ''' creates instances of alebo kernel in which distance metric is mahalonobis instead of euclidean distance.'''\n",
        "  def __init__(self,B):\n",
        "    super().__init__(has_length=False,ard_num_dims=None,eps=0.0)\n",
        "    self.d = B.shape[0]\n",
        "    self.D = B.shape[1]\n",
        "    self.B = B\n",
        "    self.Binv = torch.pinverse(B)\n",
        "    # self.dtype = B.dtype\n",
        "    # self.batch_shape = batch_shape\n",
        "\n",
        "    A = torch.qr(torch.randn(self.D,self.D))[0]\n",
        "    ABinv = A[:self.d,:] @ self.Binv\n",
        "    T = ABinv.t() @ ABinv\n",
        "    U = torch.cholesky(T,upper = True)\n",
        "    self.idx = U.nonzero().t().tolist()\n",
        "    Uvec = U[self.idx]#.repeat(*batch_shape,1)\n",
        "    # print(Uvec)\n",
        "    t = torch.tensor(2.0)\n",
        "    self.register_parameter(name = \"Uvec\",parameter=torch.nn.Parameter(Uvec))\n",
        "\n",
        "\n",
        "    \n",
        "  def forward(self,x1,x2,**params):\n",
        "    U_t = torch.zeros(self.Uvec.shape[:-1]+torch.Size([self.d,self.d]))\n",
        "    U_t[...,self.idx[1],self.idx[0]] = self.Uvec\n",
        "    z1 = x1 @ U_t\n",
        "    z2 = x2 @ U_t\n",
        "    return self.covar_dist(z1,z2,square_dist=True,dist_postprocess_func=postprocess_rbf,postprocess=True,**params)\n",
        "\n",
        "class AleboGP(gpytorch.models.ExactGP):\n",
        "  ''' Creates instance of Alebo GP by taking into account the mahalonobis kernel '''\n",
        "  def __init__(self, train_x, train_y, likelihood,B):\n",
        "    super().__init__(train_x, train_y, likelihood)\n",
        "    self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel=AleboKernel(B=B))\n",
        "    self.mean_module = gpytorch.means.ConstantMean()\n",
        "  def forward(self,x):\n",
        "    mean_x = self.mean_module(x)\n",
        "    covar_x = self.covar_module(x)\n",
        "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiwpMOWdOZTm",
        "outputId": "bc2114ca-a8f5-41cc-81e8-b181727d7801"
      },
      "source": [
        "\n",
        "def calc_grad(model,likelihood,train_x,train_y):\n",
        "  model.train()\n",
        "  likelihood.train()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
        "  mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  output = model(train_x)\n",
        "  loss = -mll(output, train_y).sum()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  model.eval()\n",
        "  likelihood.eval()\n",
        "  return model.covar_module.base_kernel.Uvec.grad\n",
        "\n",
        "def train(model,likelihood,train_x,train_y,training_iter=4000):\n",
        "  ''' Takes model and training data and return the optimised parameter of the AleboGP model'''\n",
        "# training_iter = 50\n",
        "  model.train()\n",
        "  likelihood.train()\n",
        "  print(model.parameters())\n",
        "  for params in model.parameters():\n",
        "    print(params)\n",
        "  # optimizer = adabound.AdaBound(model.parameters(), lr=1.6,final_lr = 0.05)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=.01) \n",
        "\n",
        "  mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "\n",
        "  for i in range(training_iter):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(train_x)\n",
        "  \n",
        "      loss = -mll(output, train_y).sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      params_dict = OrderedDict(mll.named_parameters())\n",
        "      # print(loss)\n",
        "      # print(params_dict)\n",
        "      # print(model.covar_module.base_kernel.)\n",
        "      # if i in [0,1]:\n",
        "        # for param_name, attr in params_dict.items():\n",
        "        #   print(param_name)\n",
        "        #   print(params_dict[param_name])\n",
        "        # print(params_dict[param_name].requires_grad)\n",
        "\n",
        "  \n",
        "  model.eval()\n",
        "  likelihood.eval()\n",
        "\n",
        "  return model,likelihood\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = AleboGP(train_x_d, train_y, likelihood,B)\n",
        "\n",
        "model,likelihood = train(model,likelihood,train_x_d,train_y)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x7f6382cb0550>\n",
            "Parameter containing:\n",
            "tensor([0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.3049, 0.6363, 0.6967], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-_keiie6Z0"
      },
      "source": [
        "def get_r2_square(model,likelihood,train_x,train_y):\n",
        "  ''' takes mode and training data and calculates r2 square score for of the model on the data'''\n",
        "  observed_pred = likelihood(model(train_x))\n",
        "  lower,upper = observed_pred.confidence_region()\n",
        "  r2_square = 0\n",
        "  sum_diff = 0\n",
        "  for i in range(train_x.shape[0]):\n",
        "    r2_square += (observed_pred.mean[i].detach().numpy()-train_y[i].numpy())**2\n",
        "  sum_diff += np.sum(upper.detach().numpy())-np.sum(lower.detach().numpy())\n",
        "\n",
        "  return r2_square,sum_diff\n",
        "    \n",
        "def get_best_fit_gp(train_x,train_y,n_trials=3):\n",
        "  ''' generates and train n_trials number of models and return the model that fits the data in the best way by using r2 square metric. '''\n",
        "  ## Use MLL if it gives poor result.\n",
        "  best_state = {}\n",
        "  r2_square = 1e9\n",
        "  for i in range(n_trials):\n",
        "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "    model = AleboGP(train_x, train_y, likelihood,B)\n",
        "\n",
        "    model,likelihood = train(model,likelihood,train_x,train_y)\n",
        "\n",
        "    r2_square_i,sum_diff_i = get_r2_square(model,likelihood,train_x,train_y)\n",
        "\n",
        "    if r2_square_i < r2_square:\n",
        "      best_state = model.state_dict()\n",
        "      r2_square = r2_square_i\n",
        "  \n",
        "  best_likelihood =gpytorch.likelihoods.GaussianLikelihood()\n",
        "  best_model = AleboGP(train_x, train_y, likelihood,B)\n",
        "  best_model.state_dict(best_state)\n",
        "\n",
        "  return best_likelihood,best_model\n",
        "\n",
        "\n",
        "# def sample_U(likelihood,model,nsamp=10):\n",
        "  # return list of Uvec for each model\n",
        "likelihood, model = get_best_fit_gp(train_x @ B.t(),train_y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yTaU6Od992q"
      },
      "source": [
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "observed_pred = likelihood(model(train_x @ B.t()))\n",
        "lower,upper = observed_pred.confidence_region()\n",
        "\n",
        "\n",
        "plt.plot(train_y, observed_pred.mean.detach().numpy(),'bo' ,label=\"Pred\")\n",
        "plt.plot(train_y,train_y,label='Ideal')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzLVvlj0C-k6"
      },
      "source": [
        "def double_derivative(i,epsilon_i,m1,m2,l1,l2,train_x,train_y):\n",
        "    '''Function which takes the models m1 and m2 (m2 is for m1+epsilon)\n",
        "        and returns the double derivative for i-th component'''\n",
        "    g1 = (m1.covar_module.base_kernel.Uvec.grad)\n",
        "    g2 = calc_grad(m2,l2,train_x,train_y)\n",
        "    return (g2[i] - g1[i])/epsilon_i\n",
        "\n",
        "\n",
        "def print_param(model):\n",
        "  print()\n",
        "  for x in model.named_parameters():\n",
        "      print(x)\n",
        "  print()\n",
        "\n",
        "def update_Uvec(model,likelihood,i,ep):\n",
        "  ''' updates the ith element of Uvec model parameter from Uvec[i] to Uvec[i]+ep and returns the model with updated parameters'''\n",
        "  model_copy = copy.deepcopy(model)\n",
        "  print_param(model_copy)\n",
        "  Uvec = model_copy.covar_module.base_kernel.Uvec\n",
        "  model_copy.covar_module.base_kernel.Uvec.requires_grad_(False)\n",
        "  Uvec[i] = Uvec[i]+ep\n",
        "  model_copy.covar_module.base_kernel.Uvec.requires_grad_(True)\n",
        "  print_param(model_copy)\n",
        "\n",
        "  return model_copy,likelihood\n",
        "\n",
        "\n",
        "def sample_U(model,likelihood,train_x,train_y,n=5):\n",
        "  '''Takes best fit model and return n model where each model's Uvec is sampled from laplace approx of MAP model(model,likelihood)'''\n",
        "  Uvec = model.covar_module.base_kernel.Uvec\n",
        "  mean_constant = model.mean_module.constant\n",
        "  output_scale = model.covar_module.raw_outputscale\n",
        "  noise_covar = model.likelihood.noise_covar.raw_noise\n",
        "\n",
        "  hessian = np.zeros((Uvec.shape[0],Uvec.shape[0]))\n",
        "  ep = 1e-3 * np.abs(Uvec.detach().numpy()) + 1e-4\n",
        "  for j in range(Uvec.shape[0]):\n",
        "    m2,l2 = update_Uvec(model,likelihood,j,ep[j])\n",
        "    hessian[j,j] = double_derivative(j,ep[j],model,m2,likelihood,l2,train_x,train_y)\n",
        "  \n",
        "  print(hessian)\n",
        "  Sigma = np.linalg.inv(-hessian)\n",
        "  samples = np.random.multivariate_normal(mean=Uvec.detach().numpy(), cov=Sigma, size=(n - 1))\n",
        "  \n",
        "\n",
        "  m_list = [model]\n",
        "  l_list = [likelihood]\n",
        "\n",
        "  for i in range(n-1):\n",
        "    new_model = copy.deepcopy(model)\n",
        "    new_likelihood = copy.deepcopy(likelihood)\n",
        "    new_model.train()\n",
        "    \n",
        "\n",
        "    new_Uvec = torch.tensor(samples[i])\n",
        "    new_model.covar_module.base_kernel.Uvec.requires_grad_(False)\n",
        "    new_model.covar_module.base_kernel.Uvec.copy_(new_Uvec)\n",
        "    new_model.covar_module.base_kernel.Uvec.requires_grad_(False)\n",
        "\n",
        "    new_model.eval()\n",
        "    new_model,new_likelihood = train(new_model,new_likelihood,train_x,train_y)\n",
        "\n",
        "    m_list.append(new_model)\n",
        "    l_list.append(new_likelihood)\n",
        "\n",
        "  \n",
        "  return m_list,l_list\n",
        "\n",
        "\n",
        "\n",
        "m_list,l_list = sample_U(model,likelihood,train_x @ B.t(),train_y)\n",
        "\n",
        "\n",
        "\n",
        "# update_Uvec(model,likelihood,0,torch.tensor(1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "N082Y_JJoWKR",
        "outputId": "27e26820-d9e5-40c5-f256-ffecd72672cd"
      },
      "source": [
        "def get_final_pred(models,likelihoods,test_x): # test_x is in n*d dimensions.returns means,variances\n",
        "    preds = [likelihood(model(test_x)) for likelihood,model in zip(likelihoods,models)]\n",
        "    means = torch.tensor([[y.mean for y in x] for x in preds]).t()\n",
        "    variances = torch.tensor([[y.variance for y in x] for x in preds]).t()\n",
        "    mu = torch.mean(means,axis=1)\n",
        "    variance = torch.mean(variances,axis=1) + torch.var(means,axis=1,unbiased=False)\n",
        "    return mu,variance\n",
        "\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "# observed_pred = likelihood(model(train_x @ B.t()))\n",
        "# lower,upper = observed_pred.confidence_region()\n",
        "y_pred,_ = get_final_pred(m_list,l_list,train_x_d)\n",
        "\n",
        "plt.plot(train_y, y_pred,'bo' ,label=\"Pred\")\n",
        "plt.plot(train_y,train_y,label='Ideal')\n",
        "plt.legend()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gpytorch/models/exact_gp.py:275: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
            "  GPInputWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f636f1d2590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuz4CZr7-Ea2",
        "outputId": "52dab5ee-0544-4476-ec58-f7452b38b7bd"
      },
      "source": [
        "def constrained_minimize(objective,Binv,x0):\n",
        "    def constraint_generator_minus_1(Binv,i):\n",
        "        def con(x):\n",
        "            x_D = Binv @ x\n",
        "            return x_D[i]+1\n",
        "        return con\n",
        "    def constraint_generator_plus_1(Binv,i):\n",
        "        def con(x):\n",
        "            x_D = Binv @ x\n",
        "            return 1-x_D[i]\n",
        "        return con\n",
        "    constraints_fun = []\n",
        "    for i in range(B.shape[0]):\n",
        "        constraints_fun.append(constraint_generator_minus_1(Binv,i))\n",
        "        constraints_fun.append(constraint_generator_plus_1(Binv,i))\n",
        "    constraints = [{'type':'ineq', 'fun':fun} for fun in constraints_fun]\n",
        "    print(constraints)\n",
        "    candidate = minimize(objective,x0,constraints=constraints,method='SLSQP')\n",
        "    return candidate\n",
        "            \n",
        "\n",
        "\n",
        "def objective(x):\n",
        "    print(\"x=\",x)\n",
        "    return x.sum()\n",
        "B = np.eye(3)\n",
        "x0 = np.array([0.5,0.5,0.5])\n",
        "constrained_minimize(objective,B,x0)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_minus_1.<locals>.con at 0x7f636f28fe60>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_plus_1.<locals>.con at 0x7f636f28fb00>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_minus_1.<locals>.con at 0x7f636f28f8c0>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_plus_1.<locals>.con at 0x7f636f28f830>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_minus_1.<locals>.con at 0x7f636f28fdd0>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_plus_1.<locals>.con at 0x7f636f28fef0>}]\n",
            "x= [0.5 0.5 0.5]\n",
            "x= [0.5 0.5 0.5]\n",
            "x= [0.50000001 0.5        0.5       ]\n",
            "x= [0.5        0.50000001 0.5       ]\n",
            "x= [0.5        0.5        0.50000001]\n",
            "x= [-0.5 -0.5 -0.5]\n",
            "x= [-0.5 -0.5 -0.5]\n",
            "x= [-0.49999999 -0.5        -0.5       ]\n",
            "x= [-0.5        -0.49999999 -0.5       ]\n",
            "x= [-0.5        -0.5        -0.49999999]\n",
            "x= [-1. -1. -1.]\n",
            "x= [-1. -1. -1.]\n",
            "x= [-0.99999999 -1.         -1.        ]\n",
            "x= [-1.         -0.99999999 -1.        ]\n",
            "x= [-1.         -1.         -0.99999999]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: -3.0000000000000133\n",
              "     jac: array([1., 1., 1.])\n",
              " message: 'Optimization terminated successfully.'\n",
              "    nfev: 15\n",
              "     nit: 3\n",
              "    njev: 3\n",
              "  status: 0\n",
              " success: True\n",
              "       x: array([-1., -1., -1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N4L_HA1DbEl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}