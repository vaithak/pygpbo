{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AleboGP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1n3QPLfkDBW",
        "outputId": "a88a0095-bbf7-4fec-84ab-65ceeff0d546"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "!pip install gpytorch\n",
        "import gpytorch\n",
        "from gpytorch.kernels.rbf_kernel import postprocess_rbf\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from collections import OrderedDict\n",
        "import copy"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from gpytorch) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gpytorch) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->gpytorch) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->gpytorch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->gpytorch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4GTLXyml8iS",
        "outputId": "c6b652e9-4855-4288-d7c4-5abf83945162"
      },
      "source": [
        "\n",
        "def function(X,noise=0):\n",
        "  def func(x):\n",
        "    return (math.pow((x[1]-5.1/(4*math.pow(3.14,2))*math.pow(x[0],2)+5/3.14*x[0]-6),2)+10*(1-1/(8*3.14))*math.cos(x[0])+10)*math.sin(x[2]/5)\n",
        "  return torch.tensor(np.apply_along_axis(func, 1, X).reshape(-1,1),dtype = torch.float32)\n",
        "\n",
        "def get_proj_matrix(D,d,hypersphere=0):\n",
        "  ''' Takes three arguments D : column size, d : row size and hypersphere = 0/1 (if hypersphere is 1 then sample each row of B from S^{D-1} else from N(0,1))\n",
        "  returns a random B matrix of shape d x D '''\n",
        "  A = np.random.normal(0,1,(d,D))\n",
        "  if hypersphere==1:\n",
        "    for row in range(d):\n",
        "      N = np.linalg.norm(A[row,:])\n",
        "      A[row,:] = A[row,:]/N\n",
        "  return A\n",
        "\n",
        "\n",
        "batch_shape = torch.Size([1])\n",
        "a1 = torch.linspace(-5, 10, 10)\n",
        "a2 = torch.linspace(0, 15, 10)\n",
        "a3 = torch.linspace(-5,5,10)\n",
        "train_x = torch.zeros((10*10*10,3),dtype=torch.float32)\n",
        "ctr=0\n",
        "for i1 in a1:\n",
        "    for i2 in a2:\n",
        "        for i3 in a3:\n",
        "            train_x[ctr,0] = i1\n",
        "            train_x[ctr,1] = i2\n",
        "            train_x[ctr,2] = i3\n",
        "            ctr+=1\n",
        "B = torch.tensor(get_proj_matrix(3,2,1),dtype=torch.float32)\n",
        "train_x_d = (train_x @ B.t())\n",
        "train_y = function(train_x)\n",
        "train_y = train_y.squeeze(1)\n",
        "\n",
        "class AleboKernel(gpytorch.kernels.Kernel):\n",
        "  ''' creates instances of alebo kernel in which distance metric is mahalonobis instead of euclidean distance.'''\n",
        "  def __init__(self,B):\n",
        "    super().__init__(has_length=False,ard_num_dims=None,eps=0.0)\n",
        "    self.d = B.shape[0]\n",
        "    self.D = B.shape[1]\n",
        "    self.B = B\n",
        "    self.Binv = torch.pinverse(B)\n",
        "    # self.dtype = B.dtype\n",
        "    # self.batch_shape = batch_shape\n",
        "\n",
        "    A = torch.qr(torch.randn(self.D,self.D))[0]\n",
        "    ABinv = A[:self.d,:] @ self.Binv\n",
        "    T = ABinv.t() @ ABinv\n",
        "    U = torch.cholesky(T,upper = True)\n",
        "    self.idx = U.nonzero().t().tolist()\n",
        "    Uvec = U[self.idx]#.repeat(*batch_shape,1)\n",
        "    print(Uvec)\n",
        "    self.register_parameter(name = \"Uvec\",parameter=torch.nn.Parameter(Uvec))\n",
        "    \n",
        "  def forward(self,x1,x2,**params):\n",
        "    U_t = torch.zeros(self.Uvec.shape[:-1]+torch.Size([self.d,self.d]))\n",
        "    U_t[...,self.idx[1],self.idx[0]] = self.Uvec\n",
        "\n",
        "    z1 = x1 @ U_t\n",
        "    z2 = x2 @ U_t\n",
        "\n",
        "    return self.covar_dist(z1,z2,square_dist=True,dist_postprocess_func=postprocess_rbf,**params)\n",
        "\n",
        "class AleboGP(gpytorch.models.ExactGP):\n",
        "  ''' Creates instance of Alebo GP by taking into account the mahalonobis kernel '''\n",
        "  def __init__(self, train_x, train_y, likelihood,B):\n",
        "    super().__init__(train_x, train_y, likelihood)\n",
        "    self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel=AleboKernel(B=B))\n",
        "    self.mean_module = gpytorch.means.ConstantMean()\n",
        "  def forward(self,x):\n",
        "    mean_x = self.mean_module(x)\n",
        "    covar_x = self.covar_module(x)\n",
        "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "model = AleboGP(train_x_d, train_y, likelihood,B)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0306, 0.2859, 0.9611])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiwpMOWdOZTm"
      },
      "source": [
        "\n",
        "def train(model,likelihood,train_x,train_y,training_iter=2000):\n",
        "  ''' Takes model and training data and return the optimised parameter of the AleboGP model'''\n",
        "# training_iter = 50\n",
        "  model.train()\n",
        "  likelihood.train()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.1) \n",
        "\n",
        "  mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "  for i in range(training_iter):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(train_x)\n",
        "  \n",
        "      loss = -mll(output, train_y).sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      params_dict = OrderedDict(mll.named_parameters())\n",
        "      print(loss)\n",
        "  \n",
        "  model.eval()\n",
        "  likelihood.eval()\n",
        "\n",
        "  return model,likelihood\n",
        "\n",
        "# model,likelihood = train(model,likelihood,train_x_d,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-_keiie6Z0"
      },
      "source": [
        "def get_r2_square(model,likelihood,train_x,train_y):\n",
        "  ''' takes mode and training data and calculates r2 square score for of the model on the data'''\n",
        "  observed_pred = likelihood(model(train_x))\n",
        "  lower,upper = observed_pred.confidence_region()\n",
        "  r2_square = 0\n",
        "  sum_diff = 0\n",
        "  for i in range(train_x.shape[0]):\n",
        "    r2_square += (observed_pred.mean[i].detach().numpy()-train_y[i].numpy())**2\n",
        "  sum_diff += np.sum(upper.detach().numpy())-np.sum(lower.detach().numpy())\n",
        "\n",
        "  return r2_square,sum_diff\n",
        "    \n",
        "def get_best_fit_gp(train_x,train_y,n_trials=1):\n",
        "  ''' generates and train n_trials number of models and return the model that fits the data in the best way by using r2 square metric. '''\n",
        "  ## Use MLL if it gives poor result.\n",
        "  best_state = {}\n",
        "  r2_square = 1e9\n",
        "  for i in range(n_trials):\n",
        "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "    model = AleboGP(train_x, train_y, likelihood,B)\n",
        "\n",
        "    model,likelihood = train(model,likelihood,train_x,train_y)\n",
        "\n",
        "    r2_square_i,sum_diff_i = get_r2_square(model,likelihood,train_x,train_y)\n",
        "\n",
        "    if r2_square_i < r2_square:\n",
        "      best_state = model.state_dict()\n",
        "      r2_square = r2_square_i\n",
        "  \n",
        "  best_likelihood =gpytorch.likelihoods.GaussianLikelihood()\n",
        "  best_model = AleboGP(train_x, train_y, likelihood,B)\n",
        "  best_model.state_dict(best_state)\n",
        "\n",
        "  return best_likelihood,best_model\n",
        "\n",
        "\n",
        "# def sample_U(likelihood,model,nsamp=10):\n",
        "  # return list of Uvec for each model\n",
        "likelihood, model = get_best_fit_gp(train_x @ B.t(),train_y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBhEaTo88bU"
      },
      "source": [
        "def get_param_hessian(model,likelihood,x0):\n",
        "  ## x0 is the model parameter at which we have to return  grad\n",
        "\n",
        "  model.train()\n",
        "  likelihood.train()\n",
        "\n",
        "  mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "  mll = set_param(mll,x0)\n",
        "  Uvev_0 = np.array([])\n",
        "  for x in mll.named_parameters():\n",
        "    param_name = x[0]\n",
        "    # param_grad = \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7yTaU6Od992q",
        "outputId": "004ba2d3-d653-40f7-8c98-1fb56bc94bee"
      },
      "source": [
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "observed_pred = likelihood(model(train_x @ B.t()))\n",
        "lower,upper = observed_pred.confidence_region()\n",
        "\n",
        "\n",
        "plt.plot(train_y, observed_pred.mean.detach().numpy(),'bo' ,label=\"Pred\")\n",
        "plt.plot(train_y,train_y,label='Ideal')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([-9.5011], grad_fn=<ViewBackward>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-aa62ce8f8bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# plt.plot(train_y,train_y,label='Ideal')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# plt.legend()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_final_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-b8cd6cbc2840>\u001b[0m in \u001b[0;36mget_final_pred\u001b[0;34m(models, test_x)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3373\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzLVvlj0C-k6",
        "outputId": "b8bc712c-63ee-4e50-9194-ac5d60b9fc6b"
      },
      "source": [
        "def double_derivative(i,epsilon_i,m1,m2,l1,l2,train_x,train_y,training_iter):\n",
        "    '''Function which takes the models m1 and m2 (m2 is for m1+epsilon)\n",
        "        and returns the double derivative for i-th component'''\n",
        "    m1,l1 = train(m1,l1,train_x,train_y,training_iter)\n",
        "    m2,l2 = train(m2,l2,train_x,train_y,training_iter)\n",
        "    g1 = (m1.covar_module.base_kernel.Uvec.grad)\n",
        "    g2 = (m2.covar_module.base_kernel.Uvec.grad)\n",
        "    return (g2[i] - g1[i])/epsilon_i\n",
        "\n",
        "\n",
        "def print_param(model):\n",
        "  print()\n",
        "  for x in model.named_parameters():\n",
        "      print(x)\n",
        "  print()\n",
        "\n",
        "def update_Uvec(model,likelihood,i,ep):\n",
        "  ''' updates the ith element of Uvec model parameter from Uvec[i] to Uvec[i]+ep and returns the model with updated parameters'''\n",
        "  model_copy = copy.deepcopy(model)\n",
        "  print_param(model_copy)\n",
        "  Uvec = model_copy.covar_module.base_kernel.Uvec\n",
        "  model_copy.covar_module.base_kernel.Uvec.requires_grad_(False)\n",
        "  Uvec[i] = Uvec[i]+ep\n",
        "  model_copy.covar_module.base_kernel.Uvec.requires_grad_(True)\n",
        "  print_param(model_copy)\n",
        "update_Uvec(model,likelihood,0,torch.tensor(1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([37.5372], requires_grad=True))\n",
            "('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True))\n",
            "('covar_module.base_kernel.Uvec', Parameter containing:\n",
            "tensor([ 0.9627, -0.3541,  0.5022], requires_grad=True))\n",
            "('mean_module.constant', Parameter containing:\n",
            "tensor([0.], requires_grad=True))\n",
            "\n",
            "\n",
            "('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([37.5372], requires_grad=True))\n",
            "('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True))\n",
            "('covar_module.base_kernel.Uvec', Parameter containing:\n",
            "tensor([ 1.9627, -0.3541,  0.5022], requires_grad=True))\n",
            "('mean_module.constant', Parameter containing:\n",
            "tensor([0.], requires_grad=True))\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CanWYC3Yov_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b07dde-09b4-47a5-9187-c714d522dae0"
      },
      "source": [
        "def get_final_pred(models,likelihoods,test_x): # test_x is in n*d dimensions.returns means,variances\n",
        "    preds = [likelihood(model(test_x @ B.t())) for likelihood,model in zip(likelihoods,models)]\n",
        "    means = torch.tensor([[y.mean for y in x] for x in preds]).t()\n",
        "    variances = torch.tensor([[y.variance for y in x] for x in preds]).t()\n",
        "    mu = torch.mean(means,axis=1)\n",
        "    variance = torch.mean(variances,axis=1) + torch.var(means,axis=1,unbiased=False)\n",
        "    return mu,variance\n",
        "\n",
        "get_final_pred([model],[likelihood],train_x[0:2,:])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-9.5011, -5.9215]), tensor([1.1790, 1.1869]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNOL6Emcea4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb25bcef-8a8a-4c53-ea3c-d97e6fc5e80e"
      },
      "source": [
        "def constrained_minimize(objective,Binv,x0):\n",
        "    def constraint_generator_minus_1(Binv,i):\n",
        "        def con(x):\n",
        "            x_D = Binv @ x\n",
        "            return x_D[i]+1\n",
        "        return con\n",
        "    def constraint_generator_plus_1(Binv,i):\n",
        "        def con(x):\n",
        "            x_D = Binv @ x\n",
        "            return 1-x_D[i]\n",
        "        return con\n",
        "    constraints_fun = []\n",
        "    for i in range(B.shape[0]):\n",
        "        constraints_fun.append(constraint_generator_minus_1(Binv,i))\n",
        "        constraints_fun.append(constraint_generator_plus_1(Binv,i))\n",
        "    constraints = [{'type':'ineq', 'fun':fun} for fun in constraints_fun]\n",
        "    print(constraints)\n",
        "    candidate = minimize(objective,x0,constraints=constraints,method='SLSQP')\n",
        "            \n",
        "\n",
        "\n",
        "def objective(x):\n",
        "    print(\"x=\",x)\n",
        "    return x.sum()\n",
        "B = np.eye(3)\n",
        "x0 = np.array([0.5,0.5,0.5])\n",
        "constrained_minimize(objective,B,x0)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_minus_1.<locals>.con at 0x7f64ae60edd0>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_plus_1.<locals>.con at 0x7f64ae60eb90>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_minus_1.<locals>.con at 0x7f64ae60ea70>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_plus_1.<locals>.con at 0x7f64ae60e4d0>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_minus_1.<locals>.con at 0x7f64ae60eb00>}, {'type': 'ineq', 'fun': <function constrained_minimize.<locals>.constraint_generator_plus_1.<locals>.con at 0x7f64ae60e440>}]\n",
            "x= [0.5 0.5 0.5]\n",
            "x= [0.5 0.5 0.5]\n",
            "x= [0.50000001 0.5        0.5       ]\n",
            "x= [0.5        0.50000001 0.5       ]\n",
            "x= [0.5        0.5        0.50000001]\n",
            "x= [-0.5 -0.5 -0.5]\n",
            "x= [-0.5 -0.5 -0.5]\n",
            "x= [-0.49999999 -0.5        -0.5       ]\n",
            "x= [-0.5        -0.49999999 -0.5       ]\n",
            "x= [-0.5        -0.5        -0.49999999]\n",
            "x= [-1. -1. -1.]\n",
            "x= [-1. -1. -1.]\n",
            "x= [-0.99999999 -1.         -1.        ]\n",
            "x= [-1.         -0.99999999 -1.        ]\n",
            "x= [-1.         -1.         -0.99999999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2bbcjS9_e6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}